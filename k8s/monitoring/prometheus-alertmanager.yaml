# Monitoring Stack — Kubernetes Manifests
#
# Prometheus + Alertmanager + Grafana + Loki
# kubectl apply -f k8s/monitoring/

---
# ── Namespace ──
apiVersion: v1
kind: Namespace
metadata:
  name: monitoring
  labels:
    kubernetes.io/metadata.name: monitoring

---
# ════════════════════════════════════════════
# PROMETHEUS
# ════════════════════════════════════════════

apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: monitoring
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      evaluation_interval: 15s
      scrape_timeout: 10s

    # ── Alerting ──
    alerting:
      alertmanagers:
        - static_configs:
            - targets: ['alertmanager:9093']

    # ── Recording & Alert Rules ──
    rule_files:
      - /etc/prometheus/rules/*.yml

    # ── Scrape Configs ──
    scrape_configs:
      # Prometheus self-monitoring
      - job_name: prometheus
        static_configs:
          - targets: ['localhost:9090']

      # ImmoflowMe application
      - job_name: immoflowme
        kubernetes_sd_configs:
          - role: pod
            namespaces:
              names: [default]
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_label_app]
            regex: immoflowme
            action: keep
          - source_labels: [__meta_kubernetes_pod_name]
            target_label: instance
          - source_labels: [__meta_kubernetes_pod_label_version]
            target_label: version
        metrics_path: /metrics
        scheme: http

      # Node exporter (if deployed)
      - job_name: node-exporter
        kubernetes_sd_configs:
          - role: node
        relabel_configs:
          - source_labels: [__address__]
            regex: (.+):(.+)
            target_label: __address__
            replacement: $1:9100

      # Kubernetes API server
      - job_name: kubernetes-apiservers
        kubernetes_sd_configs:
          - role: endpoints
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
          - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
            action: keep
            regex: default;kubernetes;https

  # ── Alert Rules ──
  alerts.yml: |
    groups:
      - name: immoflowme.slos
        interval: 30s
        rules:
          # SLO: Error rate < 1%
          - alert: HighErrorRate
            expr: |
              sum(rate(http_requests_total{status=~"5.."}[5m])) /
              sum(rate(http_requests_total[5m])) > 0.01
            for: 5m
            labels:
              severity: critical
              team: backend
            annotations:
              summary: "Error rate exceeds 1% SLO"
              description: "{{ $value | humanizePercentage }} of requests are failing (5xx)"
              runbook: "https://docs.internal/runbooks/high-error-rate"

          # SLO: p99 latency < 2s
          - alert: HighLatency
            expr: |
              histogram_quantile(0.99, rate(http_request_duration_seconds_bucket[5m])) > 2
            for: 5m
            labels:
              severity: warning
              team: backend
            annotations:
              summary: "p99 latency exceeds 2s SLO"
              description: "p99 latency is {{ $value | humanizeDuration }}"

          # SLO: Billing run < 30 min
          - alert: BillingRunSlow
            expr: |
              histogram_quantile(0.99, rate(billing_run_duration_seconds_bucket[1h])) > 1800
            for: 10m
            labels:
              severity: critical
              team: billing
            annotations:
              summary: "Billing run exceeds 30min SLO"

      - name: immoflowme.availability
        rules:
          # Pod availability
          - alert: PodCrashLooping
            expr: |
              rate(kube_pod_container_status_restarts_total{namespace="default", container="app"}[15m]) > 0
            for: 5m
            labels:
              severity: critical
            annotations:
              summary: "Pod {{ $labels.pod }} is crash-looping"

          # Memory pressure
          - alert: HighMemoryUsage
            expr: |
              container_memory_working_set_bytes{namespace="default", container="app"} /
              container_spec_memory_limit_bytes{namespace="default", container="app"} > 0.85
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "Memory usage > 85% of limit"

          # Job queue backlog
          - alert: JobQueueBacklog
            expr: job_queue_pending_total > 100
            for: 10m
            labels:
              severity: warning
              team: backend
            annotations:
              summary: "Job queue backlog exceeds 100"

      - name: immoflowme.billing
        rules:
          # Billing conflicts spike
          - alert: BillingConflictSpike
            expr: rate(billing_conflicts_total[5m]) > 0.1
            for: 5m
            labels:
              severity: warning
              team: billing
            annotations:
              summary: "Billing conflict rate elevated"

          # No billing runs in expected window
          - alert: BillingRunMissing
            expr: |
              time() - billing_last_successful_run_timestamp > 86400
            for: 1h
            labels:
              severity: warning
              team: billing
            annotations:
              summary: "No successful billing run in 24h"

---
# ── Alertmanager Config ──
apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager-config
  namespace: monitoring
data:
  alertmanager.yml: |
    global:
      resolve_timeout: 5m

    route:
      group_by: ['alertname', 'team']
      group_wait: 30s
      group_interval: 5m
      repeat_interval: 4h
      receiver: default
      routes:
        - match:
            severity: critical
          receiver: pagerduty-critical
          continue: true
        - match:
            team: billing
          receiver: billing-team
        - match:
            severity: warning
          receiver: slack-warnings

    receivers:
      - name: default
        webhook_configs:
          - url: 'http://immoflowme.default.svc/api/alerts/webhook'
            send_resolved: true

      - name: pagerduty-critical
        pagerduty_configs:
          - routing_key: '<PAGERDUTY_ROUTING_KEY>'
            severity: critical
            description: '{{ .CommonAnnotations.summary }}'

      - name: billing-team
        slack_configs:
          - api_url: '<SLACK_WEBHOOK_URL>'
            channel: '#billing-alerts'
            title: '{{ .CommonAnnotations.summary }}'
            text: '{{ .CommonAnnotations.description }}'
            send_resolved: true

      - name: slack-warnings
        slack_configs:
          - api_url: '<SLACK_WEBHOOK_URL>'
            channel: '#ops-warnings'
            send_resolved: true

    inhibit_rules:
      - source_match:
          severity: critical
        target_match:
          severity: warning
        equal: ['alertname']

---
# ════════════════════════════════════════════
# LOKI — Log Aggregation
# ════════════════════════════════════════════

apiVersion: v1
kind: ConfigMap
metadata:
  name: loki-config
  namespace: monitoring
data:
  loki.yaml: |
    auth_enabled: false

    server:
      http_listen_port: 3100

    common:
      path_prefix: /loki
      storage:
        filesystem:
          chunks_directory: /loki/chunks
          rules_directory: /loki/rules
      replication_factor: 1
      ring:
        kvstore:
          store: inmemory

    schema_config:
      configs:
        - from: 2024-01-01
          store: tsdb
          object_store: filesystem
          schema: v13
          index:
            prefix: index_
            period: 24h

    # ── Retention Policies ──
    limits_config:
      retention_period: 90d              # Default: 90 days for app logs
      max_query_series: 5000
      max_entries_limit_per_query: 10000

    # Per-tenant overrides (if multi-tenant)
    # overrides:
    #   audit:
    #     retention_period: 2557d          # 7 years (BAO compliance)

    compactor:
      working_directory: /loki/compactor
      retention_enabled: true
      retention_delete_delay: 2h
      delete_request_store: filesystem

---
# ════════════════════════════════════════════
# RETENTION POLICY DOCUMENTATION
# ════════════════════════════════════════════

apiVersion: v1
kind: ConfigMap
metadata:
  name: retention-policies
  namespace: monitoring
data:
  retention.md: |
    # Data Retention Policies — ImmoflowMe

    ## By Data Type

    | Data Type       | Retention  | Storage         | Compliance      |
    |-----------------|-----------|-----------------|-----------------|
    | Metrics         | 30 days   | Prometheus TSDB | —               |
    | App Logs        | 90 days   | Loki            | —               |
    | Audit Logs      | 7 years   | PostgreSQL+WORM | BAO §132        |
    | Traces          | 14 days   | Tempo           | —               |
    | Error Events    | 90 days   | Sentry          | —               |
    | Billing Records | 10 years  | PostgreSQL+WORM | GoBD            |
    | SBOM/Scan       | 90 days   | GitHub Artifacts| —               |

    ## WORM (Write-Once-Read-Many)

    Audit logs and billing records are protected by:
    1. DB triggers preventing UPDATE/DELETE (immutability)
    2. SHA-256 hash chain for integrity verification
    3. Periodic archive exports with checksums

    ## Prometheus Retention

    Configured via --storage.tsdb.retention.time=30d
    For long-term metrics, use Thanos or Cortex sidecar.
