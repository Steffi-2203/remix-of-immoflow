
name: Billing Parity & Release

on:
  workflow_dispatch:
    inputs:
      dry_run_only:
        description: 'Only run dry-run parity (no release)'
        required: false
        default: 'true'
        type: boolean
      run_load_test:
        description: 'Run load test after parity'
        required: false
        default: 'false'
        type: boolean
      load_test_rows:
        description: 'Number of rows for load test'
        required: false
        default: '10000'
        type: string
      load_test_parallel:
        description: 'Parallel jobs for load test'
        required: false
        default: '1'
        type: string
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

concurrency:
  group: billing-parity-${{ github.ref }}
  cancel-in-progress: true

jobs:
  test:
    name: Unit Tests
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: testdb
        ports:
          - 5432:5432
        options: >-
          --health-cmd "pg_isready -U postgres -d testdb"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    env:
      DATABASE_URL: postgres://postgres:postgres@localhost:5432/testdb
      SESSION_SECRET: ci-test-secret-not-for-production
      NODE_ENV: test

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: 20

      - name: Install dependencies
        run: npm ci --legacy-peer-deps

      - name: Wait for Postgres
        run: |
          for i in {1..30}; do pg_isready -h localhost -p 5432 && break || sleep 1; done

      - name: Bootstrap CI schema
        run: psql "$DATABASE_URL" -f ci/schema.sql

      - name: Run migrations
        run: node migrations/run-migration.cjs

      - name: Run tests
        run: npx vitest run src/test/normalizeDescription.test.ts --reporter=verbose

  billing-parity:
    name: Billing Parity & Reconciliation
    runs-on: ubuntu-latest
    needs: test
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: billing_test
        ports:
          - 5432:5432
        options: >-
          --health-cmd "pg_isready -U postgres -d billing_test"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    env:
      # Local CI DB — not a real secret, but mask it anyway
      DATABASE_URL: postgres://postgres:postgres@localhost:5432/billing_test
      SESSION_SECRET: ci-test-secret-not-for-production
      NODE_ENV: test

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: 20

      - name: Mask secrets
        run: |
          echo "::add-mask::$DATABASE_URL"
          if [ -n "${{ secrets.STAGING_DATABASE_URL }}" ]; then
            echo "::add-mask::${{ secrets.STAGING_DATABASE_URL }}"
          fi

      - name: Install dependencies
        run: npm ci --legacy-peer-deps

      - name: Wait for Postgres
        run: |
          for i in {1..30}; do pg_isready -h localhost -p 5432 && break || sleep 1; done

      - name: Bootstrap CI schema
        run: psql "$DATABASE_URL" -f ci/schema.sql

      - name: Run migrations
        run: node migrations/run-migration.cjs

      # ── Duplicate Precheck ──
      - name: Duplicate precheck
        run: |
          DUPES=$(psql "$DATABASE_URL" -t -A -c "
            SELECT count(*) FROM (
              SELECT invoice_id, unit_id, line_type,
                     regexp_replace(lower(trim(description)), '\s+', ' ', 'g') AS norm
              FROM invoice_lines
              GROUP BY invoice_id, unit_id, line_type, norm
              HAVING count(*) > 1
            ) sub;
          ")
          echo "Duplicate groups found: $DUPES"
          if [ "$DUPES" -gt 0 ]; then
            echo "::error::Found $DUPES duplicate invoice_line groups before parity run!"
            exit 1
          fi

      # ── Unit & Parity Tests ──
      - name: Run billing determinism tests
        run: npx vitest run tests/unit/billing-determinism.test.ts --reporter=verbose

      - name: Run billing service parity tests
        run: npx vitest run tests/unit/billing.service.test.ts --reporter=verbose

      - name: Run rounding & invoice tests
        run: npx vitest run tests/unit/utils.test.ts tests/unit/invoice-generation.test.ts --reporter=verbose

      - name: Run normalizeDescription parity tests
        run: npx vitest run src/test/normalizeDescription.test.ts --reporter=verbose

      # ── Dry-Run Parity Harness ──
      - name: Run parity harness (dry-run)
        id: parity
        run: |
          RUN_ID="ci-$(date +%Y%m%d-%H%M%S)-${GITHUB_SHA::8}"
          echo "run_id=$RUN_ID" >> "$GITHUB_OUTPUT"
          mkdir -p "reconciliations/$RUN_ID"

          # Execute dry-run script (produces dryrun.json)
          npx tsx scripts/dryrun.ts 2>&1 | tee "reconciliations/$RUN_ID/dryrun.log"

          # Export DB state for comparison
          psql "$DATABASE_URL" -c "
            SELECT invoice_id, unit_id, line_type, description,
                   normalized_description, amount, tax_rate
            FROM invoice_lines
            ORDER BY invoice_id, unit_id, line_type
          " --csv -o "reconciliations/$RUN_ID/db_invoice_lines.csv" 2>/dev/null || true

          # Run diff tool to find missing lines
          node tools/compare_dryrun_db.js \
            --dryrun=dryrun.json \
            --db-csv="reconciliations/$RUN_ID/db_invoice_lines.csv" \
            --output="reconciliations/$RUN_ID" 2>&1 || true

          # Check for missing lines
          MISSING_COUNT=0
          if [ -f "reconciliations/$RUN_ID/missing_lines.csv" ]; then
            MISSING_COUNT=$(tail -n +2 "reconciliations/$RUN_ID/missing_lines.csv" | wc -l | tr -d ' ')
          fi

          # Generate summary.json
          cat > "reconciliations/$RUN_ID/summary.json" <<EOF
          {
            "run_id": "$RUN_ID",
            "commit": "$GITHUB_SHA",
            "ref": "$GITHUB_REF",
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "missing_lines_count": $MISSING_COUNT,
            "parity_pass": $([ "$MISSING_COUNT" -eq 0 ] && echo true || echo false)
          }
          EOF

          # Compute SHA256 of artifacts
          sha256sum reconciliations/$RUN_ID/* > "reconciliations/$RUN_ID/checksums.sha256" 2>/dev/null || true

          echo "missing_count=$MISSING_COUNT" >> "$GITHUB_OUTPUT"

          if [ "$MISSING_COUNT" -gt 0 ]; then
            echo "::warning::Parity mismatch — $MISSING_COUNT missing lines detected (run: $RUN_ID)"
          else
            echo "✅ Parity check passed — 0 missing lines"
          fi

      # ── Upload reconciliation artifacts ──
      - name: Upload reconciliation artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: reconciliation-${{ steps.parity.outputs.run_id }}
          path: reconciliations/${{ steps.parity.outputs.run_id }}/*
          retention-days: 90

      # ── Fail if parity mismatch ──
      - name: Fail on parity mismatch
        if: steps.parity.outputs.missing_count != '0'
        run: |
          echo "::error::PARITY FAILED — ${{ steps.parity.outputs.missing_count }} missing lines."
          echo "Download the reconciliation-missing artifact for details."
          exit 1

  load-test:
    name: Load Test (${{ matrix.name }})
    runs-on: ubuntu-latest
    needs: billing-parity
    timeout-minutes: 30
    if: github.event_name == 'workflow_dispatch' && github.event.inputs.run_load_test == 'true'

    strategy:
      fail-fast: false
      matrix:
        include:
          - name: "S1-10k"
            rows: 10000
            parallel: 1
          - name: "S2-50k"
            rows: 50000
            parallel: 1
          - name: "S3-100k"
            rows: 100000
            parallel: 4

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: loadtest
        ports:
          - 5432:5432
        options: >-
          --health-cmd "pg_isready -U postgres -d loadtest"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    env:
      DATABASE_URL: postgres://postgres:postgres@localhost:5432/loadtest
      STAGING_DATABASE_URL: postgres://postgres:postgres@localhost:5432/loadtest
      SESSION_SECRET: ci-test-secret-not-for-production
      NODE_ENV: test

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: 20

      - name: Install dependencies
        run: npm ci --legacy-peer-deps

      - name: Wait for Postgres
        run: |
          for i in {1..30}; do pg_isready -h localhost -p 5432 && break || sleep 1; done

      - name: Bootstrap CI schema
        run: psql "$DATABASE_URL" -f ci/schema.sql

      - name: Run migrations
        run: node migrations/run-migration.cjs

      - name: Capture WAL position before
        id: wal_before
        run: |
          WAL_BEFORE=$(psql "$DATABASE_URL" -t -A -c "SELECT pg_current_wal_lsn();")
          echo "lsn=$WAL_BEFORE" >> "$GITHUB_OUTPUT"

      - name: Seed test data for load test
        run: |
          ROWS=${{ matrix.rows }}
          INVOICE_COUNT=$(( (ROWS + 9) / 10 ))

          psql "$DATABASE_URL" -c "
            INSERT INTO properties (id, name, address, city, postal_code, created_at)
            VALUES ('00000000-0000-0000-0000-000000000001', 'Load Test Property', 'Test 1', 'Wien', '1010', now())
            ON CONFLICT DO NOTHING;
          "

          psql "$DATABASE_URL" -c "
            INSERT INTO units (id, property_id, top_nummer, flaeche, nutzwert, created_at, updated_at)
            SELECT
              '00000000-0000-0000-0000-' || lpad((2000 + g)::text, 12, '0'),
              '00000000-0000-0000-0000-000000000001',
              'LT-' || g,
              50, 100, now(), now()
            FROM generate_series(0, 99) g
            ON CONFLICT DO NOTHING;
          "

          psql "$DATABASE_URL" -c "
            INSERT INTO tenants (id, unit_id, first_name, last_name, email, created_at, updated_at)
            VALUES (
              '00000000-0000-0000-0000-000000009000',
              '00000000-0000-0000-0000-000000002000',
              'Load', 'Test', 'loadtest@test.local', now(), now()
            )
            ON CONFLICT DO NOTHING;
          "

          psql "$DATABASE_URL" -c "
            INSERT INTO monthly_invoices (id, tenant_id, unit_id, year, month, faellig_am, created_at)
            SELECT
              '00000000-0000-0000-0000-' || lpad((1000 + g)::text, 12, '0'),
              '00000000-0000-0000-0000-000000009000',
              '00000000-0000-0000-0000-' || lpad((2000 + (g % 100))::text, 12, '0'),
              2025,
              1 + (g % 12),
              '2025-01-15',
              now()
            FROM generate_series(0, ${INVOICE_COUNT} - 1) g
            ON CONFLICT DO NOTHING;
          "

          echo "Seeded: 1 property, 100 units, 1 tenant, $INVOICE_COUNT invoices"

      - name: Run load test
        id: loadtest
        run: |
          chmod +x tools/load_test_bulk.sh
          START_EPOCH=$(date +%s%3N)
          bash tools/load_test_bulk.sh \
            ${{ matrix.rows }} \
            ${{ matrix.parallel }} \
            "$DATABASE_URL" 2>&1 | tee load_test_output.log
          END_EPOCH=$(date +%s%3N)
          DURATION_MS=$((END_EPOCH - START_EPOCH))
          echo "duration_ms=$DURATION_MS" >> "$GITHUB_OUTPUT"

      - name: Collect metrics
        id: metrics
        run: |
          SCENARIO="${{ matrix.name }}"
          ROWS=${{ matrix.rows }}
          PARALLEL=${{ matrix.parallel }}
          DURATION_MS=${{ steps.loadtest.outputs.duration_ms }}

          # DB settings
          WORK_MEM=$(psql "$DATABASE_URL" -t -A -c "SHOW work_mem;")
          MAX_WAL=$(psql "$DATABASE_URL" -t -A -c "SHOW max_wal_size;")
          MAX_CONN=$(psql "$DATABASE_URL" -t -A -c "SHOW max_connections;")
          SHARED_BUF=$(psql "$DATABASE_URL" -t -A -c "SHOW shared_buffers;")

          # WAL diff
          WAL_BEFORE="${{ steps.wal_before.outputs.lsn }}"
          WAL_AFTER=$(psql "$DATABASE_URL" -t -A -c "SELECT pg_current_wal_lsn();")
          WAL_BYTES=$(psql "$DATABASE_URL" -t -A -c "SELECT pg_wal_lsn_diff('${WAL_AFTER}', '${WAL_BEFORE}');")
          WAL_MB=$(echo "scale=2; ${WAL_BYTES:-0} / 1048576" | bc)

          # Row counts
          INSERTED=$(psql "$DATABASE_URL" -t -A -c "SELECT count(*) FROM invoice_lines WHERE created_at >= now() - interval '30 min';")

          # Duplicates
          DUPES=$(psql "$DATABASE_URL" -t -A -c "
            SELECT count(*) FROM (
              SELECT invoice_id, unit_id, line_type,
                     regexp_replace(lower(trim(description)), '\s+', ' ', 'g') AS norm
              FROM invoice_lines
              GROUP BY invoice_id, unit_id, line_type, norm
              HAVING count(*) > 1
            ) sub;
          ")

          # PG version
          PG_VERSION=$(psql "$DATABASE_URL" -t -A -c "SELECT version();")

          mkdir -p "load_tests/${SCENARIO}"
          cat > "load_tests/${SCENARIO}/metrics.json" <<EOF
          {
            "scenario": "${SCENARIO}",
            "rows": ${ROWS},
            "parallel": ${PARALLEL},
            "duration_ms": ${DURATION_MS:-0},
            "duration_s": $(echo "scale=2; ${DURATION_MS:-0} / 1000" | bc),
            "inserted": ${INSERTED:-0},
            "duplicates": ${DUPES:-0},
            "wal_mb": ${WAL_MB:-0},
            "work_mem": "${WORK_MEM}",
            "max_wal_size": "${MAX_WAL}",
            "max_connections": "${MAX_CONN}",
            "shared_buffers": "${SHARED_BUF}",
            "pg_version": "${PG_VERSION}",
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "commit": "${GITHUB_SHA}"
          }
          EOF

          echo "Metrics written to load_tests/${SCENARIO}/metrics.json"
          cat "load_tests/${SCENARIO}/metrics.json"

          if [ "$DUPES" -gt 0 ]; then
            echo "::warning::Found $DUPES duplicate groups after load test ${SCENARIO}"
          fi

      - name: Upload load test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: load-test-${{ matrix.name }}
          path: |
            load_test_output.log
            load_tests/
          retention-days: 30

  pr-gate:
    name: PR Gate (required)
    runs-on: ubuntu-latest
    needs: [test, billing-parity]
    if: always()
    steps:
      - name: Check required jobs
        run: |
          echo "Test result: ${{ needs.test.result }}"
          echo "Billing Parity result: ${{ needs.billing-parity.result }}"

          if [ "${{ needs.test.result }}" != "success" ]; then
            echo "::error::Unit Tests failed or were skipped"
            exit 1
          fi

          if [ "${{ needs.billing-parity.result }}" != "success" ]; then
            echo "::error::Billing Parity failed or was skipped"
            exit 1
          fi

          echo "✅ All required checks passed — PR is ready to merge"
