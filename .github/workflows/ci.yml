
name: Billing Parity & Release

on:
  workflow_dispatch:
    inputs:
      dry_run_only:
        description: 'Only run dry-run parity (no release)'
        required: false
        default: 'true'
        type: boolean
      run_load_test:
        description: 'Run load test after parity'
        required: false
        default: 'false'
        type: boolean
      load_test_rows:
        description: 'Number of rows for load test'
        required: false
        default: '10000'
        type: string
      load_test_parallel:
        description: 'Parallel jobs for load test'
        required: false
        default: '1'
        type: string
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

concurrency:
  group: billing-parity-${{ github.ref }}
  cancel-in-progress: true

jobs:
  test:
    name: Unit Tests
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: testdb
        ports:
          - 5432:5432
        options: >-
          --health-cmd "pg_isready -U postgres -d testdb"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    env:
      DATABASE_URL: postgres://postgres:postgres@localhost:5432/testdb
      SESSION_SECRET: ci-test-secret-not-for-production
      NODE_ENV: test

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: 20

      - name: Install dependencies
        run: npm ci --legacy-peer-deps

      - name: Wait for Postgres
        run: |
          for i in {1..30}; do pg_isready -h localhost -p 5432 && break || sleep 1; done

      - name: Bootstrap CI schema
        run: psql "$DATABASE_URL" -f ci/schema.sql

      - name: Run migrations
        run: node migrations/run-migration.cjs

      - name: Run tests
        run: npx vitest run src/test/normalizeDescription.test.ts --reporter=verbose

  billing-parity:
    name: Billing Parity & Reconciliation
    runs-on: ubuntu-latest
    needs: test
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: billing_test
        ports:
          - 5432:5432
        options: >-
          --health-cmd "pg_isready -U postgres -d billing_test"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    env:
      # Local CI DB — not a real secret, but mask it anyway
      DATABASE_URL: postgres://postgres:postgres@localhost:5432/billing_test
      SESSION_SECRET: ci-test-secret-not-for-production
      NODE_ENV: test

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: 20

      - name: Mask secrets
        run: |
          echo "::add-mask::$DATABASE_URL"
          if [ -n "${{ secrets.STAGING_DATABASE_URL }}" ]; then
            echo "::add-mask::${{ secrets.STAGING_DATABASE_URL }}"
          fi

      - name: Install dependencies
        run: npm ci --legacy-peer-deps

      - name: Wait for Postgres
        run: |
          for i in {1..30}; do pg_isready -h localhost -p 5432 && break || sleep 1; done

      - name: Bootstrap CI schema
        run: psql "$DATABASE_URL" -f ci/schema.sql

      - name: Run migrations
        run: node migrations/run-migration.cjs

      # ── Schema Compatibility Gate ──
      - name: Schema compatibility gate
        run: |
          chmod +x tools/schema_compat_check.sh
          bash tools/schema_compat_check.sh

      - name: DR restore test
        run: |
          chmod +x tools/dr_restore_test.sh
          bash tools/dr_restore_test.sh || echo "::warning::DR restore test had issues (non-blocking)"

      - name: Security audit
        run: |
          chmod +x tools/security_audit.sh
          bash tools/security_audit.sh || echo "::warning::Security audit found issues (review required)"

      - name: Duplicate precheck
        run: |
          DUPES=$(psql "$DATABASE_URL" -t -A -c "
            SELECT count(*) FROM (
              SELECT invoice_id, unit_id, line_type,
                     regexp_replace(lower(trim(description)), '\s+', ' ', 'g') AS norm
              FROM invoice_lines
              GROUP BY invoice_id, unit_id, line_type, norm
              HAVING count(*) > 1
            ) sub;
          ")
          echo "Duplicate groups found: $DUPES"
          if [ "$DUPES" -gt 0 ]; then
            echo "::error::Found $DUPES duplicate invoice_line groups before parity run!"
            exit 1
          fi

      # ── Unit & Parity Tests ──
      - name: Run billing determinism tests
        run: npx vitest run tests/unit/billing-determinism.test.ts --reporter=verbose

      - name: Run billing service parity tests
        run: npx vitest run tests/unit/billing.service.test.ts --reporter=verbose

      - name: Run rounding & invoice tests
        run: npx vitest run tests/unit/utils.test.ts tests/unit/invoice-generation.test.ts --reporter=verbose

      - name: Run normalizeDescription parity tests
        run: npx vitest run src/test/normalizeDescription.test.ts --reporter=verbose

      # ── Dry-Run Parity Harness ──
      - name: Run parity harness (dry-run)
        id: parity
        run: |
          RUN_ID="ci-$(date +%Y%m%d-%H%M%S)-${GITHUB_SHA::8}"
          echo "run_id=$RUN_ID" >> "$GITHUB_OUTPUT"
          mkdir -p "reconciliations/$RUN_ID"

          # Execute dry-run script (produces dryrun.json)
          npx tsx scripts/dryrun.ts 2>&1 | tee "reconciliations/$RUN_ID/dryrun.log"

          # Export DB state for comparison
          psql "$DATABASE_URL" -c "
            SELECT invoice_id, unit_id, line_type, description,
                   normalized_description, amount, tax_rate
            FROM invoice_lines
            ORDER BY invoice_id, unit_id, line_type
          " --csv -o "reconciliations/$RUN_ID/db_invoice_lines.csv" 2>/dev/null || true

          # Run diff tool to find missing lines
          node tools/compare_dryrun_db.js \
            --dryrun=dryrun.json \
            --db-csv="reconciliations/$RUN_ID/db_invoice_lines.csv" \
            --output="reconciliations/$RUN_ID" 2>&1 || true

          # Check for missing lines
          MISSING_COUNT=0
          if [ -f "reconciliations/$RUN_ID/missing_lines.csv" ]; then
            MISSING_COUNT=$(tail -n +2 "reconciliations/$RUN_ID/missing_lines.csv" | wc -l | tr -d ' ')
          fi

          # Generate summary.json
          cat > "reconciliations/$RUN_ID/summary.json" <<EOF
          {
            "run_id": "$RUN_ID",
            "commit": "$GITHUB_SHA",
            "ref": "$GITHUB_REF",
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "missing_lines_count": $MISSING_COUNT,
            "parity_pass": $([ "$MISSING_COUNT" -eq 0 ] && echo true || echo false)
          }
          EOF

          # Compute SHA256 of artifacts
          sha256sum reconciliations/$RUN_ID/* > "reconciliations/$RUN_ID/checksums.sha256" 2>/dev/null || true

          echo "missing_count=$MISSING_COUNT" >> "$GITHUB_OUTPUT"

          if [ "$MISSING_COUNT" -gt 0 ]; then
            echo "::warning::Parity mismatch — $MISSING_COUNT missing lines detected (run: $RUN_ID)"
          else
            echo "✅ Parity check passed — 0 missing lines"
          fi

      # ── Export audit package ──
      - name: Export audit package
        if: always()
        env:
          S3_BUCKET: ${{ secrets.S3_BUCKET }}
          AWS_REGION: eu-central-1
          LOVABLE_API_URL: ${{ secrets.LOVABLE_API_URL }}
          LOVABLE_API_TOKEN: ${{ secrets.LOVABLE_API_TOKEN }}
        run: |
          RUN_ID="${{ steps.parity.outputs.run_id }}"
          STORAGE="local"
          EXTRA_ARGS=""
          if [ -n "$S3_BUCKET" ]; then
            STORAGE="s3"
            EXTRA_ARGS="--s3-bucket $S3_BUCKET"
          elif [ -n "$LOVABLE_API_URL" ] && [ -n "$LOVABLE_API_TOKEN" ]; then
            STORAGE="lovable"
          fi
          node tools/export_audit_package.js \
            --run-id "$RUN_ID" \
            --out "audit_exports" \
            --storage "$STORAGE" \
            $EXTRA_ARGS || echo "::warning::Audit package export failed (non-blocking)"

      # ── Upload reconciliation artifacts ──
      - name: Upload reconciliation artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: reconciliation-${{ steps.parity.outputs.run_id }}
          path: |
            reconciliations/${{ steps.parity.outputs.run_id }}/*
            audit_exports/${{ steps.parity.outputs.run_id }}/*
          retention-days: 90

      # ── Fail if parity mismatch ──
      - name: Fail on parity mismatch
        if: steps.parity.outputs.missing_count != '0'
        run: |
          echo "::error::PARITY FAILED — ${{ steps.parity.outputs.missing_count }} missing lines."
          echo "Download the reconciliation-missing artifact for details."
          exit 1

  load-test:
    name: Load Test (${{ matrix.name }})
    runs-on: ubuntu-latest
    needs: billing-parity
    timeout-minutes: 30
    if: github.event_name == 'workflow_dispatch' && github.event.inputs.run_load_test == 'true'

    strategy:
      fail-fast: false
      matrix:
        include:
          - name: "S1-10k"
            rows: 10000
            parallel: 1
          - name: "S2-50k"
            rows: 50000
            parallel: 1
          - name: "S3-100k"
            rows: 100000
            parallel: 4

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: loadtest
        ports:
          - 5432:5432
        options: >-
          --health-cmd "pg_isready -U postgres -d loadtest"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    env:
      DATABASE_URL: postgres://postgres:postgres@localhost:5432/loadtest
      STAGING_DATABASE_URL: postgres://postgres:postgres@localhost:5432/loadtest
      SESSION_SECRET: ci-test-secret-not-for-production
      NODE_ENV: test

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: 20

      - name: Install dependencies
        run: npm ci --legacy-peer-deps

      - name: Wait for Postgres
        run: |
          for i in {1..30}; do pg_isready -h localhost -p 5432 && break || sleep 1; done

      - name: Bootstrap CI schema
        run: psql "$DATABASE_URL" -f ci/schema.sql

      - name: Run migrations
        run: node migrations/run-migration.cjs

      - name: Tune Postgres for load test
        run: |
          psql "$DATABASE_URL" -c "ALTER SYSTEM SET max_wal_size = '4GB';"
          psql "$DATABASE_URL" -c "ALTER SYSTEM SET checkpoint_timeout = '30min';"
          psql "$DATABASE_URL" -c "SELECT pg_reload_conf();"
          echo "Applied bulk window tuning: max_wal_size=4GB, checkpoint_timeout=30min"

      - name: Capture WAL position before
        id: wal_before
        run: |
          WAL_BEFORE=$(psql "$DATABASE_URL" -t -A -c "SELECT pg_current_wal_lsn();")
          echo "lsn=$WAL_BEFORE" >> "$GITHUB_OUTPUT"

      - name: Seed test data for load test
        run: |
          ROWS=${{ matrix.rows }}
          INVOICE_COUNT=$(( (ROWS + 9) / 10 ))

          psql "$DATABASE_URL" -c "
            INSERT INTO properties (id, name, address, city, postal_code, created_at)
            VALUES ('00000000-0000-0000-0000-000000000001', 'Load Test Property', 'Test 1', 'Wien', '1010', now())
            ON CONFLICT DO NOTHING;
          "

          psql "$DATABASE_URL" -c "
            INSERT INTO units (id, property_id, top_nummer, flaeche, nutzwert, created_at, updated_at)
            SELECT
              '00000000-0000-0000-0000-' || lpad((2000 + g)::text, 12, '0'),
              '00000000-0000-0000-0000-000000000001',
              'LT-' || g,
              50, 100, now(), now()
            FROM generate_series(0, 99) g
            ON CONFLICT DO NOTHING;
          "

          psql "$DATABASE_URL" -c "
            INSERT INTO tenants (id, unit_id, first_name, last_name, email, created_at, updated_at)
            VALUES (
              '00000000-0000-0000-0000-000000009000',
              '00000000-0000-0000-0000-000000002000',
              'Load', 'Test', 'loadtest@test.local', now(), now()
            )
            ON CONFLICT DO NOTHING;
          "

          psql "$DATABASE_URL" -c "
            INSERT INTO monthly_invoices (id, tenant_id, unit_id, year, month, faellig_am, created_at)
            SELECT
              '00000000-0000-0000-0000-' || lpad((1000 + g)::text, 12, '0'),
              '00000000-0000-0000-0000-000000009000',
              '00000000-0000-0000-0000-' || lpad((2000 + (g % 100))::text, 12, '0'),
              2025,
              1 + (g % 12),
              '2025-01-15',
              now()
            FROM generate_series(0, ${INVOICE_COUNT} - 1) g
            ON CONFLICT DO NOTHING;
          "

          echo "Seeded: 1 property, 100 units, 1 tenant, $INVOICE_COUNT invoices"

      - name: Run load test
        id: loadtest
        run: |
          chmod +x tools/load_test_bulk.sh
          bash tools/load_test_bulk.sh \
            ${{ matrix.rows }} \
            ${{ matrix.parallel }} \
            "$DATABASE_URL" \
            "${{ matrix.name }}" 2>&1 | tee load_test_output.log

          # Find the metrics.json that was just written
          LATEST_DIR=$(ls -td load_tests/*/ 2>/dev/null | head -1)
          if [ -n "$LATEST_DIR" ] && [ -f "${LATEST_DIR}metrics.json" ]; then
            DURATION_MS=$(node -e "console.log(JSON.parse(require('fs').readFileSync('${LATEST_DIR}metrics.json','utf8')).duration_ms)")
            echo "duration_ms=$DURATION_MS" >> "$GITHUB_OUTPUT"
            echo "metrics_dir=$LATEST_DIR" >> "$GITHUB_OUTPUT"
            # Copy to scenario-named dir for report generator
            mkdir -p "load_tests/${{ matrix.name }}"
            cp "${LATEST_DIR}metrics.json" "load_tests/${{ matrix.name }}/metrics.json"
            cp "${LATEST_DIR}locks.log" "load_tests/${{ matrix.name }}/locks.log" 2>/dev/null || true
          fi

      - name: Acceptance gate
        if: always()
        run: |
          SCENARIO="${{ matrix.name }}"
          METRICS_FILE="load_tests/${SCENARIO}/metrics.json"
          if [ ! -f "$METRICS_FILE" ]; then
            echo "::warning::No metrics file found for ${SCENARIO}"
            exit 0
          fi

          echo "── Acceptance Results for ${SCENARIO} ──"
          node -e "
            const m = JSON.parse(require('fs').readFileSync('${METRICS_FILE}', 'utf8'));
            let pass = true;

            // Gate 1: Duration SLA (100k < 30 min)
            if (m.duration_s > 1800) {
              console.log('❌ Duration ' + m.duration_s + 's exceeds 1800s SLA');
              pass = false;
            } else {
              console.log('✅ Duration ' + m.duration_s + 's within SLA');
            }

            // Gate 2: No locks > 30s
            if (m.max_lock_wait_ms > 30000) {
              console.log('❌ Max lock wait ' + m.max_lock_wait_ms + 'ms exceeds 30s');
              pass = false;
            } else {
              console.log('✅ Max lock wait ' + m.max_lock_wait_ms + 'ms within 30s');
            }

            // Gate 3: Zero duplicates
            if (m.duplicates > 0) {
              console.log('❌ ' + m.duplicates + ' duplicate groups');
              pass = false;
            } else {
              console.log('✅ Zero duplicates');
            }

            // Gate 4: Conflict rate
            if (m.conflict_rate > 0.10) {
              console.log('⚠️  Conflict rate ' + (m.conflict_rate * 100).toFixed(1) + '% exceeds 10%');
            } else {
              console.log('✅ Conflict rate ' + (m.conflict_rate * 100).toFixed(1) + '%');
            }

            console.log('');
            console.log('Throughput: ' + m.rows_per_second + ' rows/s');
            console.log('WAL: ' + m.wal_mb + ' MB');
            console.log('Settings: work_mem=' + m.pg_settings.work_mem + ' max_wal_size=' + m.pg_settings.max_wal_size);

            if (!pass) process.exit(1);
          "

      - name: Reset Postgres tuning
        if: always()
        run: |
          psql "$DATABASE_URL" -c "ALTER SYSTEM RESET max_wal_size;" 2>/dev/null || true
          psql "$DATABASE_URL" -c "ALTER SYSTEM RESET checkpoint_timeout;" 2>/dev/null || true
          psql "$DATABASE_URL" -c "SELECT pg_reload_conf();" 2>/dev/null || true

      - name: Upload load test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: load-test-${{ matrix.name }}
          path: |
            load_test_output.log
            load_tests/
          retention-days: 30

  e2e:
    name: E2E Tests (Playwright)
    runs-on: ubuntu-latest
    needs: billing-parity
    timeout-minutes: 15
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: e2edb
        ports:
          - 5432:5432
        options: >-
          --health-cmd "pg_isready -U postgres -d e2edb"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    env:
      DATABASE_URL: postgres://postgres:postgres@localhost:5432/e2edb
      SESSION_SECRET: ci-test-secret-not-for-production
      NODE_ENV: test
      CI: true

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: 20

      - name: Install dependencies
        run: npm ci --legacy-peer-deps

      - name: Install Playwright browsers
        run: npx playwright install --with-deps chromium

      - name: Wait for Postgres
        run: |
          for i in {1..30}; do pg_isready -h localhost -p 5432 && break || sleep 1; done

      - name: Bootstrap CI schema
        run: psql "$DATABASE_URL" -f ci/schema.sql

      - name: Run migrations
        run: node migrations/run-migration.cjs

      - name: Run Playwright tests
        run: npx playwright test --project=chromium --reporter=list
        env:
          BASE_URL: http://localhost:5173

      - name: Upload Playwright report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: playwright-report
          path: |
            playwright-report/
            test-results/
          retention-days: 14

  pr-gate:
    name: PR Gate (required)
    runs-on: ubuntu-latest
    needs: [test, billing-parity, e2e]
    if: always()
    steps:
      - name: Check required jobs
        run: |
          echo "Test result: ${{ needs.test.result }}"
          echo "Billing Parity result: ${{ needs.billing-parity.result }}"
          echo "E2E result: ${{ needs.e2e.result }}"

          if [ "${{ needs.test.result }}" != "success" ]; then
            echo "::error::Unit Tests failed or were skipped"
            exit 1
          fi

          if [ "${{ needs.billing-parity.result }}" != "success" ]; then
            echo "::error::Billing Parity failed or was skipped"
            exit 1
          fi

          if [ "${{ needs.e2e.result }}" != "success" ]; then
            echo "::error::E2E Tests failed or were skipped"
            exit 1
          fi

          echo "✅ All required checks passed — PR is ready to merge"
